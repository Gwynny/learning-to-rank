{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RankNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$C_{ij}=C(o_{ij})=-\\bar{P_{ij}}log(P_{ij})-(1-\\bar{P_{ij}})log(1-P_{ij})$$\n"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%latex\n",
    "$$C_{ij}=C(o_{ij})=-\\bar{P_{ij}}log(P_{ij})-(1-\\bar{P_{ij}})log(1-P_{ij})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$o_{ij}=f(x_i)-f(x_j)$$\n"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%latex\n",
    "$$o_{ij}=f(x_i)-f(x_j)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$P_{ij}=\\frac{e^{o_{ij}}}{1+e^{o_{ij}}}$$\n"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%latex\n",
    "$$P_{ij}=\\frac{e^{o_{ij}}}{1+e^{o_{ij}}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "sigmoid() missing 1 required positional arguments: \"input\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_23716/126372968.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: sigmoid() missing 1 required positional arguments: \"input\""
     ]
    }
   ],
   "source": [
    "torch.sigmoid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$\\text{out}_{i} = \\frac{1}{1 + e^{-\\text{input}_{i}}}$$\n"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%latex\n",
    "$$\\text{out}_{i} = \\frac{1}{1 + e^{-\\text{input}_{i}}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RankNet(torch.nn.Module):\n",
    "    def __init__(self, num_input_features, hidden_dim=10):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.model = torch.nn.Sequential(\n",
    "            torch.nn.Linear(num_input_features, self.hidden_dim),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(self.hidden_dim, 1),\n",
    "        )\n",
    "        \n",
    "        self.out_activation = torch.nn.Sigmoid()\n",
    "\n",
    "    def forward(self, input_1, input_2):\n",
    "        logits_1 = self.predict(input_1)\n",
    "        logits_2 = self.predict(input_2)\n",
    "        \n",
    "        logits_diff = logits_1 - logits_2\n",
    "        out = self.out_activation(logits_diff)\n",
    "\n",
    "        return out\n",
    "    \n",
    "    def predict(self, inp):\n",
    "        logits = self.model(inp)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranknet_model = RankNet(num_input_features=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4737, 0.3166, 0.5947, 0.9229, 0.8446, 0.3150, 0.4467, 0.7716, 0.4611,\n",
       "         0.7093],\n",
       "        [0.9518, 0.4163, 0.1700, 0.1561, 0.0695, 0.6232, 0.6392, 0.9687, 0.2451,\n",
       "         0.9066],\n",
       "        [0.9838, 0.0995, 0.8838, 0.6342, 0.2499, 0.5543, 0.5031, 0.6127, 0.3663,\n",
       "         0.9750],\n",
       "        [0.8561, 0.2213, 0.6429, 0.4844, 0.3372, 0.2926, 0.8280, 0.2087, 0.4599,\n",
       "         0.0081]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp_1, inp_2 = torch.rand(4, 10), torch.rand(4, 10)\n",
    "# batch_size x input_dim\n",
    "inp_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5138],\n",
       "        [0.4839],\n",
       "        [0.4896],\n",
       "        [0.5484]], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = ranknet_model(inp_1, inp_2)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_linear_layer = ranknet_model.model[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_linear_layer.weight.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.BCELoss()\n",
    "loss = criterion(preds, torch.ones_like(preds))\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.5911e-02, -3.4822e-02,  3.9106e-03,  2.3812e-02,  5.7420e-03,\n",
       "         -4.7057e-04, -1.6776e-03,  1.2583e-02, -2.2965e-03,  3.5100e-02],\n",
       "        [ 1.7269e-02,  8.9985e-03,  3.9080e-03,  1.6665e-02,  9.8740e-03,\n",
       "          4.6578e-03,  1.9981e-02,  1.5860e-04,  9.3742e-03,  9.4872e-04],\n",
       "        [ 1.6274e-02, -1.1552e-02,  2.8733e-03,  1.5211e-02,  5.5440e-03,\n",
       "          1.2973e-03,  5.7065e-03,  5.2672e-03,  2.0515e-03,  1.4855e-02],\n",
       "        [-1.9514e-03, -1.1457e-02, -1.9429e-02, -2.1092e-03, -1.1832e-02,\n",
       "         -9.5252e-03, -6.3733e-03, -1.9986e-02, -1.1543e-02, -3.3493e-03],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 5.3690e-03, -7.2154e-03,  8.1030e-04,  4.9340e-03,  1.1898e-03,\n",
       "         -9.7507e-05, -3.4760e-04,  2.6074e-03, -4.7585e-04,  7.2729e-03],\n",
       "        [ 3.9103e-02, -5.2550e-02,  5.9015e-03,  3.5935e-02,  8.6653e-03,\n",
       "         -7.1016e-04, -2.5316e-03,  1.8990e-02, -3.4657e-03,  5.2969e-02],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 1.1152e-02,  2.6752e-02,  9.1630e-03,  2.6064e-02,  1.2063e-02,\n",
       "          1.0570e-02,  2.0123e-02, -2.1415e-02,  1.4651e-02, -1.7018e-02],\n",
       "        [ 7.4970e-03, -5.0684e-03, -3.2135e-03,  4.0591e-03, -2.6227e-03,\n",
       "          2.2121e-03,  2.2907e-05, -8.2024e-05, -1.6612e-03,  7.8622e-03]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_linear_layer.weight.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranknet_model.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ListNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "import numpy as np\n",
    "\n",
    "from utils.metrics import ndcg, num_swapped_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ListNet(torch.nn.Module):\n",
    "    def __init__(self, num_input_features, hidden_dim=10):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.model = torch.nn.Sequential(\n",
    "            torch.nn.Linear(num_input_features, self.hidden_dim),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(self.hidden_dim, 1),\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, input_1):\n",
    "        logits = self.model(input_1)\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$CE = -\\sum ^{N}_{j=1} (P_y^i(j) * log(P_z^i(j)))$$\n"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%latex\n",
    "$$CE = -\\sum ^{N}_{j=1} (P_y^i(j) * log(P_z^i(j)))$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$\\text{Softmax}(x_{i}) = \\frac{\\exp(x_i)}{\\sum_j \\exp(x_j)}$$\n"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%latex\n",
    "$$\\text{Softmax}(x_{i}) = \\frac{\\exp(x_i)}{\\sum_j \\exp(x_j)}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def listnet_ce_loss(y_i, z_i):\n",
    "    \"\"\"\n",
    "    y_i: (n_i, 1) GT\n",
    "    z_i: (n_i, 1) preds\n",
    "    \"\"\"\n",
    "\n",
    "    P_y_i = torch.softmax(y_i, dim=0)\n",
    "    P_z_i = torch.softmax(z_i, dim=0)\n",
    "    return -torch.sum(P_y_i * torch.log(P_z_i))\n",
    "\n",
    "def listnet_kl_loss(y_i, z_i):\n",
    "    \"\"\"\n",
    "    y_i: (n_i, 1) GT\n",
    "    z_i: (n_i, 1) preds\n",
    "    \"\"\"\n",
    "    P_y_i = torch.softmax(y_i, dim=0)\n",
    "    P_z_i = torch.softmax(z_i, dim=0)\n",
    "    return -torch.sum(P_y_i * torch.log(P_z_i/P_y_i))\n",
    "\n",
    "\n",
    "def make_dataset(N_train, N_valid, vector_dim):\n",
    "    fake_weights = torch.randn(vector_dim, 1)\n",
    "\n",
    "    X_train = torch.randn(N_train, vector_dim)\n",
    "    X_valid = torch.randn(N_valid, vector_dim)\n",
    "\n",
    "    ys_train_score = torch.mm(X_train, fake_weights)\n",
    "    ys_train_score += torch.randn_like(ys_train_score)\n",
    "\n",
    "    ys_valid_score = torch.mm(X_valid, fake_weights)\n",
    "    ys_valid_score += torch.randn_like(ys_valid_score)\n",
    "\n",
    "#     bins = [-1, 1]  # 3 relevances\n",
    "    bins = [-1, 0, 1, 2]  # 5 relevances\n",
    "    ys_train_rel = torch.Tensor(\n",
    "        np.digitize(ys_train_score.clone().detach().numpy(), bins=bins)\n",
    "    )\n",
    "    ys_valid_rel = torch.Tensor(\n",
    "        np.digitize(ys_valid_score.clone().detach().numpy(), bins=bins)\n",
    "    )\n",
    "\n",
    "    return X_train, X_valid, ys_train_rel, ys_valid_rel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_train = 1000\n",
    "N_valid = 500\n",
    "\n",
    "vector_dim = 100\n",
    "epochs = 2\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "X_train, X_valid, ys_train, ys_valid = make_dataset(N_train, N_valid, vector_dim)\n",
    "\n",
    "net = ListNet(num_input_features=vector_dim)\n",
    "opt = torch.optim.Adam(net.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 1., 2., 3., 4.])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.unique(ys_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1.\tNumber of swapped pairs: 0/124750\tnDCG: 1.0000\n",
      "epoch: 1.\tNumber of swapped pairs: 0/124750\tnDCG: 1.0000\n",
      "epoch: 1.\tNumber of swapped pairs: 0/124750\tnDCG: 1.0000\n",
      "epoch: 1.\tNumber of swapped pairs: 0/124750\tnDCG: 1.0000\n",
      "epoch: 1.\tNumber of swapped pairs: 0/124750\tnDCG: 1.0000\n",
      "epoch: 1.\tNumber of swapped pairs: 0/124750\tnDCG: 1.0000\n",
      "epoch: 1.\tNumber of swapped pairs: 0/124750\tnDCG: 1.0000\n",
      "epoch: 2.\tNumber of swapped pairs: 0/124750\tnDCG: 1.0000\n",
      "epoch: 2.\tNumber of swapped pairs: 0/124750\tnDCG: 1.0000\n",
      "epoch: 2.\tNumber of swapped pairs: 0/124750\tnDCG: 1.0000\n",
      "epoch: 2.\tNumber of swapped pairs: 0/124750\tnDCG: 1.0000\n",
      "epoch: 2.\tNumber of swapped pairs: 0/124750\tnDCG: 1.0000\n",
      "epoch: 2.\tNumber of swapped pairs: 0/124750\tnDCG: 1.0000\n",
      "epoch: 2.\tNumber of swapped pairs: 0/124750\tnDCG: 1.0000\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    idx = torch.randperm(N_train)\n",
    "\n",
    "    X_train = X_train[idx]\n",
    "    ys_train = ys_train[idx]\n",
    "\n",
    "    cur_batch = 0\n",
    "    for it in range(N_train // batch_size):\n",
    "        batch_X = X_train[cur_batch: cur_batch + batch_size]\n",
    "        batch_ys = ys_train[cur_batch: cur_batch + batch_size]\n",
    "        cur_batch += batch_size\n",
    "\n",
    "        opt.zero_grad()\n",
    "        if len(batch_X) > 0:\n",
    "            batch_pred = net(batch_X)\n",
    "            batch_loss = listnet_kl_loss(batch_ys, batch_pred)\n",
    "#             batch_loss = listnet_ce_loss(batch_ys, batch_pred)\n",
    "            batch_loss.backward(retain_graph=True)\n",
    "            opt.step()\n",
    "\n",
    "        if it % 10 == 0:\n",
    "            with torch.no_grad():\n",
    "                valid_pred = net(X_valid)\n",
    "                valid_swapped_pairs = num_swapped_pairs(ys_valid, valid_pred)\n",
    "                ndcg_score = ndcg(ys_valid, valid_pred)\n",
    "            print(f\"epoch: {epoch + 1}.\\tNumber of swapped pairs: \" \n",
    "                  f\"{valid_swapped_pairs}/{N_valid * (N_valid - 1) // 2}\\t\"\n",
    "                  f\"nDCG: {ndcg_score.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
