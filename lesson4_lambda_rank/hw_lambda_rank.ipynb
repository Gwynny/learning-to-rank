{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "f691f98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import optuna\n",
    "import pickle\n",
    "from typing import List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from catboost.datasets import msrank_10k\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from torch import Tensor\n",
    "\n",
    "\n",
    "class Solution:\n",
    "    def __init__(self, n_estimators: int = 231,\n",
    "                 lr: float = 0.39127022258826616,\n",
    "                 ndcg_top_k: int = 10,\n",
    "                 subsample: float = 0.53005362889185,\n",
    "                 colsample_bytree: float = 0.6304279014613413,\n",
    "                 max_depth: int = 9,\n",
    "                 min_samples_leaf: int = 25):\n",
    "        self._prepare_data()\n",
    "        self.num_input_features = self.X_train.shape[1]\n",
    "        self.num_train_objects = self.X_train.shape[0]\n",
    "        self.unique_train_groups = np.unique(self.query_ids_train)\n",
    "        self.num_test_objects = self.X_test.shape[0]\n",
    "        self.num_features_to_choice = int(colsample_bytree *\n",
    "                                          self.num_input_features)\n",
    "        self.num_groups_to_choice = int(\n",
    "            subsample * len(self.unique_train_groups))\n",
    "\n",
    "        self.ndcg_top_k = ndcg_top_k\n",
    "        self.n_estimators = n_estimators\n",
    "        self.lr = lr\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_leaf = min_samples_leaf\n",
    "\n",
    "        self.trees = []\n",
    "        self.best_ndcg = -1\n",
    "\n",
    "    def _get_data(self) -> List[np.ndarray]:\n",
    "        try:\n",
    "            train_df, test_df = msrank_10k()\n",
    "        except:\n",
    "            train_df, test_df = msrank_10k()\n",
    "\n",
    "        X_train = train_df.drop([0, 1], axis=1).values\n",
    "        y_train = train_df[0].values\n",
    "        query_ids_train = train_df[1].values.astype(int)\n",
    "\n",
    "        X_test = test_df.drop([0, 1], axis=1).values\n",
    "        y_test = test_df[0].values\n",
    "        query_ids_test = test_df[1].values.astype(int)\n",
    "\n",
    "        return [X_train, y_train, query_ids_train, X_test, y_test,\n",
    "                query_ids_test]\n",
    "\n",
    "    def _prepare_data(self) -> None:\n",
    "        (X_train, y_train, self.query_ids_train,\n",
    "         X_test, y_test, self.query_ids_test) = self._get_data()\n",
    "        # допишите ваш код здесь\n",
    "        X_train = self._scale_features_in_query_groups(\n",
    "            X_train, self.query_ids_train\n",
    "        )\n",
    "        X_test = self._scale_features_in_query_groups(\n",
    "            X_test, self.query_ids_test\n",
    "        )\n",
    "\n",
    "        self.X_train = torch.from_numpy(X_train).type(torch.FloatTensor)\n",
    "        self.ys_train = torch.from_numpy(y_train).type(\n",
    "            torch.FloatTensor).reshape(-1, 1)\n",
    "        self.X_test = torch.from_numpy(X_test).type(torch.FloatTensor)\n",
    "        self.ys_test = torch.from_numpy(y_test).type(\n",
    "            torch.FloatTensor).reshape(-1, 1)\n",
    "\n",
    "    def _scale_features_in_query_groups(self, inp_feat_array: np.ndarray,\n",
    "                                        inp_query_ids: np.ndarray) -> \\\n",
    "            np.ndarray:\n",
    "        # допишите ваш код здесь\n",
    "        for query_id in np.unique(inp_query_ids):\n",
    "            mask = inp_query_ids == query_id\n",
    "            scaler = StandardScaler()\n",
    "            scaled_part = scaler.fit_transform(inp_feat_array[mask])\n",
    "            inp_feat_array[mask] = scaled_part\n",
    "        return inp_feat_array\n",
    "\n",
    "    def _train_one_tree(self, cur_tree_idx: int,\n",
    "                        train_preds: torch.FloatTensor\n",
    "                        ) -> Tuple[DecisionTreeRegressor, np.ndarray]:\n",
    "        # допишите ваш код здесь\n",
    "        lambdas = np.zeros((self.num_train_objects, 1))\n",
    "        groups_to_train_on = np.random.choice(self.unique_train_groups,\n",
    "                                              size=self.num_groups_to_choice,\n",
    "                                              replace=False)\n",
    "        for query_id in groups_to_train_on:\n",
    "            mask = self.query_ids_train == query_id\n",
    "            group_y = self.ys_train[mask]\n",
    "            group_preds = train_preds[mask]\n",
    "            group_lambdas = self._compute_lambdas(group_y, group_preds)\n",
    "            lambdas[mask] = group_lambdas.numpy()\n",
    "\n",
    "        dt = DecisionTreeRegressor(max_depth=self.max_depth,\n",
    "                                   min_samples_leaf=self.min_samples_leaf,\n",
    "                                   random_state=cur_tree_idx)\n",
    "\n",
    "        rows = np.isin(self.query_ids_train, groups_to_train_on)\n",
    "        cols = np.random.choice(np.arange(self.num_input_features),\n",
    "                                size=self.num_features_to_choice,\n",
    "                                replace=False)\n",
    "\n",
    "        sample_X_train = self.X_train[rows][:, cols].numpy()\n",
    "        lambdas = lambdas[rows]\n",
    "        dt.fit(sample_X_train, lambdas)\n",
    "        return dt, cols\n",
    "\n",
    "    def fit(self):\n",
    "        np.random.seed(0)\n",
    "        # допишите ваш код здесь\n",
    "        best_ndcg_ind = max_ndcg = 0\n",
    "        prev_preds = torch.zeros(\n",
    "            self.num_train_objects, 1).type(torch.FloatTensor)\n",
    "        valid_preds = torch.zeros(\n",
    "            self.num_test_objects, 1).type(torch.FloatTensor)\n",
    "\n",
    "        for idx in range(1, self.n_estimators + 1):\n",
    "            dt, train_cols = self._train_one_tree(idx, prev_preds)\n",
    "            self.trees.append((dt, train_cols))\n",
    "            prev_preds -= self.lr * torch.FloatTensor(dt.predict(\n",
    "                self.X_train[:, train_cols].numpy())).reshape(-1, 1)\n",
    "            valid_preds -= self.lr * torch.FloatTensor(dt.predict(\n",
    "                self.X_test[:, train_cols].numpy())).reshape(-1, 1)\n",
    "            ndcg = self._calc_data_ndcg(self.query_ids_test, self.ys_test,\n",
    "                                        valid_preds)\n",
    "\n",
    "            if ndcg > self.best_ndcg:\n",
    "                best_ndcg_ind = idx\n",
    "                self.best_ndcg = ndcg\n",
    "                \n",
    "        self.trees = self.trees[:best_ndcg_ind]\n",
    "\n",
    "    def predict(self, data: torch.FloatTensor) -> torch.FloatTensor:\n",
    "        preds = torch.zeros(data.shape[0], 1).type(torch.FloatTensor)\n",
    "        for dt, cols in self.trees:\n",
    "            tmp_preds = dt.predict(data[:, cols].numpy())\n",
    "            preds -= self.lr * torch.FloatTensor(tmp_preds).reshape(-1, 1)\n",
    "        return preds\n",
    "\n",
    "    def _compute_lambdas(self, y_true: torch.FloatTensor,\n",
    "                         y_pred: torch.FloatTensor) -> Tensor:\n",
    "        def compute_ideal_dcg(ys_true: torch.Tensor) -> float:\n",
    "            ys_true, _ = torch.sort(ys_true, dim=0, descending=True)\n",
    "\n",
    "            sum_dcg = 0\n",
    "            for i, y_true in enumerate(ys_true, 1):\n",
    "                sum_dcg += (2 ** y_true - 1) / math.log2(i + 1)\n",
    "            return sum_dcg\n",
    "\n",
    "        def compute_labels_in_batch(y_true):\n",
    "            rel_diff = y_true - y_true.t()\n",
    "            pos_pairs = (rel_diff > 0).type(torch.float32)\n",
    "            neg_pairs = (rel_diff < 0).type(torch.float32)\n",
    "            Sij = pos_pairs - neg_pairs\n",
    "            return Sij\n",
    "\n",
    "        _, rank_order = torch.sort(y_true, descending=True, dim=0)\n",
    "        rank_order += 1\n",
    "\n",
    "        pos_pairs_score_diff = 1.0 + torch.exp((y_pred - y_pred.t()))\n",
    "\n",
    "        Sij = compute_labels_in_batch(y_true)\n",
    "\n",
    "        gain_diff = torch.pow(2.0, y_true) - torch.pow(2.0, y_true.t())\n",
    "        decay_diff = (1.0 / torch.log2(rank_order + 1.0)) - (\n",
    "                1.0 / torch.log2(rank_order.t() + 1.0))\n",
    "        ideal_dcg = compute_ideal_dcg(y_true)\n",
    "        N = 1 / (ideal_dcg + 1)\n",
    "        delta_ndcg = torch.abs(N * gain_diff * decay_diff)\n",
    "\n",
    "        lambda_update = (0.5 * (\n",
    "                    1 - Sij) - 1 / pos_pairs_score_diff) * delta_ndcg\n",
    "        lambda_update = torch.sum(lambda_update, dim=1, keepdim=True)\n",
    "        return lambda_update\n",
    "\n",
    "    def _dcg(self, ys_true: torch.Tensor, ys_pred: torch.Tensor,\n",
    "             k: int) -> float:\n",
    "        ys_pred, indices = torch.sort(ys_pred, dim=0, descending=True)\n",
    "        ys_true = ys_true[indices[:k]]\n",
    "\n",
    "        sum_dcg = 0\n",
    "        for i, y_true in enumerate(ys_true, 1):\n",
    "            sum_dcg += (2 ** y_true - 1) / math.log2(i + 1)\n",
    "        return sum_dcg\n",
    "\n",
    "    def _ndcg_k(self, ys_true: torch.Tensor, ys_pred: torch.Tensor,\n",
    "                ndcg_top_k: int) -> float:\n",
    "        ideal_dcg = self._dcg(ys_true, ys_true, ndcg_top_k)\n",
    "        case_dcg = self._dcg(ys_true, ys_pred, ndcg_top_k)\n",
    "        return float(case_dcg / ideal_dcg)\n",
    "\n",
    "    def _calc_data_ndcg(self, queries_list: np.ndarray,\n",
    "                        true_labels: torch.FloatTensor,\n",
    "                        preds: torch.FloatTensor) -> float:\n",
    "        # допишите ваш код здесь\n",
    "        unique_queries = np.unique(queries_list)\n",
    "        ndcgs = []\n",
    "        for query_id in unique_queries:\n",
    "            group_y = true_labels[queries_list == query_id]\n",
    "            y_pred = preds[queries_list == query_id]\n",
    "            group_dcg = self._ndcg_k(group_y, y_pred, self.ndcg_top_k)\n",
    "            if np.isnan(group_dcg):\n",
    "                ndcgs.append(0)\n",
    "                continue\n",
    "            ndcgs.append(group_dcg)\n",
    "        return float(np.mean(ndcgs))\n",
    "\n",
    "    def save_model(self, path: str):\n",
    "        state = {\n",
    "            'trees': self.trees,\n",
    "            'lr': self.lr,\n",
    "            'best_ndcg': self.best_ndcg\n",
    "        }\n",
    "        f = open(path, 'wb')\n",
    "        pickle.dump(state, f)\n",
    "\n",
    "    def load_model(self, path: str):\n",
    "        f = open(path, 'rb')\n",
    "        state = pickle.load(f)\n",
    "        self.trees = state['trees']\n",
    "        self.lr = state['lr']\n",
    "        self.best_ndcg = state['best_ndcg']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "01f92fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = msrank_10k()\n",
    "X_train = train_df.drop([0, 1], axis=1).values\n",
    "y_train = train_df[0].values\n",
    "query_ids_train = train_df[1].values.astype(int)\n",
    "\n",
    "X_test = test_df.drop([0, 1], axis=1).values\n",
    "y_test = test_df[0].values\n",
    "query_ids_test = test_df[1].values.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "0579f5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = torch.from_numpy(X_test)\n",
    "y_test = torch.from_numpy(y_test).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "e4bcddc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = {'lr': 0.39127022258826616, 'subsample': 0.53005362889185, 'colsample_bytree': 0.6304279014613413, 'n_estimators': 231, 'max_depth': 9, 'min_samples_leaf': 25}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "aa7129ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "slt = Solution(**best_params)\n",
    "slt.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "0a1b698c",
   "metadata": {},
   "outputs": [],
   "source": [
    "slt.save_model('model.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "d14463ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.405036643242732"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_preds = slt.predict(X_test)\n",
    "ndcg = slt._calc_data_ndcg(query_ids_test, y_test, valid_preds)\n",
    "ndcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "36116137",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial, X_test=X_test, y_test=y_test, query_ids_test=query_ids_test):\n",
    "    param = {\n",
    "        'lr': trial.suggest_float('lr', 1e-2, 7e-1),\n",
    "        'subsample': trial.suggest_float('subsample', 5e-1, 75e-2),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 5e-1, 75e-2),\n",
    "        'n_estimators': trial.suggest_categorical('n_estimators', list(range(100, 300))),\n",
    "        'max_depth': trial.suggest_categorical('max_depth', list(range(3, 10))),\n",
    "        'min_samples_leaf': trial.suggest_categorical('min_samples_leaf', list(range(5, 30))),\n",
    "    }\n",
    "    \n",
    "    model = Solution(**param)\n",
    "    model.fit()\n",
    "    \n",
    "    valid_preds = model.predict(X_test)\n",
    "    ndcg = model._calc_data_ndcg(query_ids_test, y_test, valid_preds)\n",
    "    return ndcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9521075d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=200)\n",
    "\n",
    "print('Number of finished trials:', len(study.trials))\n",
    "print('Best trial:', study.best_trial.params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "719766b5",
   "metadata": {},
   "source": [
    "Number of finished trials: 200\n",
    "\n",
    "Best trial: {'lr': 0.39127022258826616, 'subsample': 0.53005362889185, 'colsample_bytree': 0.6304279014613413, 'n_estimators': 231, 'max_depth': 9, 'min_samples_leaf': 25}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4335ffab",
   "metadata": {},
   "source": [
    "### STM solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "7da02726",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pickle\n",
    "import random\n",
    "from typing import List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from catboost.datasets import msrank_10k\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "class Solution:\n",
    "    def __init__(self, n_estimators: int = 100, lr: float = 0.5, ndcg_top_k: int = 10,\n",
    "                 subsample: float = 0.6, colsample_bytree: float = 0.9,\n",
    "                 max_depth: int = 7, min_samples_leaf: int = 8):\n",
    "        self._prepare_data()\n",
    "        self.num_input_features = self.X_train.shape[1]\n",
    "        self.num_train_objects = self.X_train.shape[0]\n",
    "        self.num_test_objects = self.X_test.shape[0]\n",
    "\n",
    "        self.features_to_choice = int(\n",
    "            self.num_input_features * colsample_bytree)\n",
    "        self.objects_to_choice = int(self.num_train_objects * subsample)\n",
    "\n",
    "        self.ndcg_top_k = ndcg_top_k\n",
    "        self.n_estimators = n_estimators\n",
    "        self.lr = lr\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_leaf = min_samples_leaf\n",
    "\n",
    "        self.trees = None\n",
    "        self.trees_feat_idxs = None\n",
    "        self.best_ndcg = -1\n",
    "        self.best_iter_idx = -1\n",
    "\n",
    "    def _get_data(self) -> List[np.array]:\n",
    "        try:\n",
    "            train_df, test_df = msrank_10k()\n",
    "        except:\n",
    "            train_df, test_df = msrank_10k()\n",
    "        X_train = train_df.drop([0, 1], axis=1).values\n",
    "        y_train = train_df[0].values\n",
    "        query_ids_train = train_df[1].values.astype(int)\n",
    "\n",
    "        X_test = test_df.drop([0, 1], axis=1).values\n",
    "        y_test = test_df[0].values\n",
    "        query_ids_test = test_df[1].values.astype(int)\n",
    "\n",
    "        return [X_train, y_train, query_ids_train, X_test, y_test, query_ids_test]\n",
    "\n",
    "    def _prepare_data(self) -> None:\n",
    "        (X_train, y_train, self.query_ids_train,\n",
    "            X_test, y_test, self.query_ids_test) = self._get_data()\n",
    "\n",
    "        X_train = self._scale_features_in_query_groups(\n",
    "            X_train, self.query_ids_train)\n",
    "        X_test = self._scale_features_in_query_groups(\n",
    "            X_test, self.query_ids_test)\n",
    "\n",
    "        self.X_train = torch.FloatTensor(X_train)\n",
    "        self.X_test = torch.FloatTensor(X_test)\n",
    "\n",
    "        self.ys_train = torch.FloatTensor(y_train).reshape(-1, 1)\n",
    "        self.ys_test = torch.FloatTensor(y_test).reshape(-1, 1)\n",
    "\n",
    "    def _scale_features_in_query_groups(self, inp_feat_array: np.array,\n",
    "                                        inp_query_ids: np.array) -> np.array:\n",
    "        for cur_id in np.unique(inp_query_ids):\n",
    "            mask = inp_query_ids == cur_id\n",
    "            tmp_array = inp_feat_array[mask]\n",
    "            scaler = StandardScaler()\n",
    "            inp_feat_array[mask] = scaler.fit_transform(tmp_array)\n",
    "\n",
    "        return inp_feat_array\n",
    "\n",
    "    def _train_one_tree(self, cur_tree_idx: int,\n",
    "                        train_preds: torch.FloatTensor\n",
    "                        ) -> Tuple[DecisionTreeRegressor, np.array]:\n",
    "        lambdas = torch.zeros(self.num_train_objects, 1)\n",
    "        for cur_id in np.unique(self.query_ids_train):\n",
    "            train_mask = self.query_ids_train == cur_id\n",
    "            lambda_update = self._compute_lambdas(\n",
    "                self.ys_train[train_mask], train_preds[train_mask])\n",
    "            if any(torch.isnan(lambda_update)):\n",
    "                lambda_update = torch.zeros_like(lambda_update)\n",
    "            lambdas[train_mask] = lambda_update\n",
    "\n",
    "        tree = DecisionTreeRegressor(\n",
    "            max_depth=self.max_depth, min_samples_leaf=self.min_samples_leaf, random_state=cur_tree_idx)\n",
    "\n",
    "        this_tree_feats = np.random.choice(\n",
    "            list(range(self.num_input_features)), self.features_to_choice, replace=False)\n",
    "        this_tree_objs = np.random.choice(\n",
    "            list(range(self.num_train_objects)), self.objects_to_choice, replace=False)\n",
    "\n",
    "        tree.fit(\n",
    "            self.X_train[this_tree_objs.reshape(-1)\n",
    "                         ][:, this_tree_feats].numpy(),\n",
    "            -lambdas[this_tree_objs.reshape(-1), :].numpy()\n",
    "        )\n",
    "\n",
    "        return tree, this_tree_feats\n",
    "\n",
    "    def _calc_data_ndcg(self, queries_list: np.array,\n",
    "                        true_labels: torch.FloatTensor, preds: torch.FloatTensor) -> float:\n",
    "        ndcgs = []\n",
    "        for cur_id in np.unique(queries_list):\n",
    "            mask = queries_list == cur_id\n",
    "            cur_ndcg = self._ndcg_k(\n",
    "                true_labels[mask], preds[mask], self.ndcg_top_k)\n",
    "            if np.isnan(cur_ndcg):\n",
    "                ndcgs.append(0)\n",
    "                continue\n",
    "            ndcgs.append(cur_ndcg)\n",
    "        return np.mean(ndcgs)\n",
    "\n",
    "    def fit(self):\n",
    "        np.random.seed(0)\n",
    "        self.trees = []\n",
    "        self.trees_feat_idxs = []\n",
    "        self.best_ndcg = -1\n",
    "        self.best_iter_idx = -1\n",
    "\n",
    "        train_preds = torch.zeros(self.num_train_objects, 1)\n",
    "        test_preds = torch.zeros(self.num_test_objects, 1)\n",
    "\n",
    "        train_ndcgs, test_ndcgs = [], []\n",
    "\n",
    "        #p_bar = tqdm(range(self.n_estimators))\n",
    "        for cur_tree_idx in range(self.n_estimators):\n",
    "            tree, this_tree_feats = self._train_one_tree(\n",
    "                cur_tree_idx, train_preds)\n",
    "            self.trees.append(tree)\n",
    "            self.trees_feat_idxs.append(this_tree_feats)\n",
    "\n",
    "            cur_tree_train_data = self.X_train[:, this_tree_feats].numpy()\n",
    "            train_preds += self.lr * \\\n",
    "                torch.FloatTensor(tree.predict(\n",
    "                    cur_tree_train_data)).reshape(-1, 1)\n",
    "            train_ndcg = self._calc_data_ndcg(\n",
    "                self.query_ids_train, self.ys_train, train_preds)\n",
    "\n",
    "            cur_tree_test_data = self.X_test[:, this_tree_feats].numpy()\n",
    "            test_preds += self.lr * \\\n",
    "                torch.FloatTensor(tree.predict(\n",
    "                    cur_tree_test_data)).reshape(-1, 1)\n",
    "            test_ndcg = self._calc_data_ndcg(\n",
    "                self.query_ids_test, self.ys_test, test_preds)\n",
    "\n",
    "            if self.best_ndcg < test_ndcg:\n",
    "                self.best_ndcg = test_ndcg\n",
    "                self.best_iter_idx = cur_tree_idx\n",
    "\n",
    "            train_ndcgs.append(train_ndcg)\n",
    "            test_ndcgs.append(test_ndcg)\n",
    "#             p_bar.set_description_str(\n",
    "#                 f'Test nDCG@{self.ndcg_top_k}={round(test_ndcg, 5)}')\n",
    "\n",
    "        cut_idx = self.best_iter_idx + 1\n",
    "        self.trees = self.trees[:cut_idx]\n",
    "        self.trees_feat_idxs = self.trees_feat_idxs[:cut_idx]\n",
    "\n",
    "    def predict(self, data: torch.FloatTensor) -> torch.FloatTensor:\n",
    "        preds = torch.zeros(data.shape[0], 1)\n",
    "        for cur_tree_idx in range(len(self.trees)):\n",
    "            tree = self.trees[cur_tree_idx]\n",
    "            feat_idx = self.trees_feat_idxs[cur_tree_idx]\n",
    "            tmp_preds = tree.predict(data[:, feat_idx].numpy())\n",
    "            preds += self.lr * torch.FloatTensor(tmp_preds).reshape(-1, 1)\n",
    "\n",
    "        return preds\n",
    "\n",
    "    def _compute_ideal_dcg(self, ys_true: torch.FloatTensor) -> float:\n",
    "        def dcg(ys_true, ys_pred):\n",
    "            _, argsort = torch.sort(ys_pred, descending=True, dim=0)\n",
    "            ys_true_sorted = ys_true[argsort]\n",
    "            ret = 0\n",
    "            for i, l in enumerate(ys_true_sorted, 1):\n",
    "                ret += (2 ** l - 1) / np.log2(1 + i)\n",
    "            return ret\n",
    "        ideal_dcg = dcg(ys_true, ys_true)\n",
    "        return ideal_dcg\n",
    "\n",
    "    def _compute_lambdas(self, y_true, y_pred):\n",
    "        # рассчитаем нормировку, IdealDCG\n",
    "        ideal_dcg = self._compute_ideal_dcg(y_true)\n",
    "        N = 1 / ideal_dcg\n",
    "\n",
    "        # рассчитаем порядок документов согласно оценкам релевантности\n",
    "        _, rank_order = torch.sort(y_true, descending=True, axis=0)\n",
    "        rank_order += 1\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # получаем все попарные разницы скоров в батче\n",
    "            pos_pairs_score_diff = 1.0 + torch.exp((y_pred - y_pred.t()))\n",
    "\n",
    "            # поставим разметку для пар, 1 если первый документ релевантнее\n",
    "            # -1 если второй документ релевантнее\n",
    "            Sij = self._compute_labels_in_batch(y_true)\n",
    "            # посчитаем изменение gain из-за перестановок\n",
    "            gain_diff = self._compute_gain_diff(y_true)\n",
    "\n",
    "            # посчитаем изменение знаменателей-дискаунтеров\n",
    "            decay_diff = (1.0 / torch.log2(rank_order + 1.0)) - \\\n",
    "                (1.0 / torch.log2(rank_order.t() + 1.0))\n",
    "            # посчитаем непосредственное изменение nDCG\n",
    "            delta_ndcg = torch.abs(N * gain_diff * decay_diff)\n",
    "            # посчитаем лямбды\n",
    "            lambda_update = (0.5 * (1 - Sij) - 1 /\n",
    "                             pos_pairs_score_diff) * delta_ndcg\n",
    "            lambda_update = torch.sum(lambda_update, dim=1, keepdim=True)\n",
    "\n",
    "            return lambda_update\n",
    "\n",
    "    def _compute_labels_in_batch(self, y_true):\n",
    "        rel_diff = y_true - y_true.t()\n",
    "        pos_pairs = (rel_diff > 0).type(torch.float32)\n",
    "        neg_pairs = (rel_diff < 0).type(torch.float32)\n",
    "        Sij = pos_pairs - neg_pairs\n",
    "        return Sij\n",
    "\n",
    "    def _compute_gain_diff(self, y_true):\n",
    "        gain_diff = torch.pow(2.0, y_true) - torch.pow(2.0, y_true.t())\n",
    "        return gain_diff\n",
    "\n",
    "    def _ndcg_k(self, ys_true, ys_pred, ndcg_top_k) -> float:\n",
    "        def dcg(ys_true, ys_pred):\n",
    "            _, argsort = torch.sort(ys_pred, descending=True, dim=0)\n",
    "            argsort = argsort[:ndcg_top_k]\n",
    "            ys_true_sorted = ys_true[argsort]\n",
    "            ret = 0\n",
    "            for i, l in enumerate(ys_true_sorted, 1):\n",
    "                ret += (2 ** l - 1) / math.log2(1 + i)\n",
    "            return ret\n",
    "        ideal_dcg = dcg(ys_true, ys_true)\n",
    "        pred_dcg = dcg(ys_true, ys_pred)\n",
    "        return (pred_dcg / ideal_dcg).item()\n",
    "\n",
    "    def save_model(self, path: str):\n",
    "        state = {\n",
    "            'trees': self.trees,\n",
    "            'trees_feat_idxs': self.trees_feat_idxs,\n",
    "            'best_ndcg': self.best_ndcg,\n",
    "            'lr': self.lr\n",
    "        }\n",
    "        f = open(path, 'wb')\n",
    "        pickle.dump(state, f)\n",
    "\n",
    "    def load_model(self, path: str):\n",
    "        f = open(path, 'rb')\n",
    "        state = pickle.load(f)\n",
    "        self.trees = state['trees']\n",
    "        self.trees_feat_idxs = state['trees_feat_idxs']\n",
    "        self.best_ndcg = state['best_ndcg']\n",
    "        self.lr = state['lr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "b72b0f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial, X_test=X_test, y_test=y_test, query_ids_test=query_ids_test):\n",
    "    param = {\n",
    "        'lr': trial.suggest_float('lr', 1e-2, 7e-1),\n",
    "        'subsample': trial.suggest_float('subsample', 5e-1, 75e-2),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 5e-1, 75e-2),\n",
    "        'n_estimators': trial.suggest_categorical('n_estimators', list(range(100, 300))),\n",
    "        'max_depth': trial.suggest_categorical('max_depth', list(range(3, 10))),\n",
    "        'min_samples_leaf': trial.suggest_categorical('min_samples_leaf', list(range(5, 30))),\n",
    "    }\n",
    "    \n",
    "    model = Solution(**param)\n",
    "    model.fit()\n",
    "    \n",
    "    valid_preds = model.predict(X_test)\n",
    "    ndcg = model._calc_data_ndcg(query_ids_test, y_test, valid_preds)\n",
    "    return ndcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff7860df",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=200)\n",
    "print('Number of finished trials:', len(study.trials))\n",
    "print('Best trial:', study.best_trial.params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e160ac72",
   "metadata": {},
   "source": [
    "Number of finished trials: 200\n",
    "\n",
    "Best trial: {'lr': 0.5099655429753616, 'subsample': 0.6540233528557746, 'colsample_bytree': 0.6343128384876874, 'n_estimators': 260, 'max_depth': 3, 'min_samples_leaf': 12}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "e7e2c939",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = study.best_trial.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "e43b9be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "slt = Solution(**best_params)\n",
    "slt.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "487a875b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.40230476581879465"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_preds = slt.predict(X_test)\n",
    "ndcg = slt._calc_data_ndcg(query_ids_test, y_test, valid_preds)\n",
    "ndcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "87e999d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "slt.save_model('stm.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9aff5a",
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
